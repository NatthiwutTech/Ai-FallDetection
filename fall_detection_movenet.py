import cv2
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from collections import deque, defaultdict
import math
import time

# Configuration - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
CONFIG = {
    'confidence_threshold': 0.25,      # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.3 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    'keypoint_threshold': 0.08,        # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏∏‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    'min_keypoints': 4,                # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏•‡∏≤‡∏î‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô
    'frame_buffer_size': 8,            # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 10 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    'fall_buffer_size': 4,             # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    'alert_cooldown': 25,              # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 30 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    'person_tracking_threshold': 0.12, # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.15 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    'resize_width': 640,
    'resize_height': 480,
    'input_size': 256
}

# ‡πÇ‡∏´‡∏•‡∏î MoveNet MultiPose model
print("Loading MoveNet model...")
model = hub.load("https://tfhub.dev/google/movenet/multipose/lightning/1")
movenet = model.signatures['serving_default']
print("Model loaded successfully!")

class PersonTracker:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô"""
    def __init__(self):
        self.persons = {}
        self.next_id = 0
        self.max_distance = CONFIG['person_tracking_threshold']
        
    def update(self, keypoints_list):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"""
        if not keypoints_list:
            return []
            
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì center point ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô
        centers = []
        for keypoints in keypoints_list:
            valid_points = keypoints[keypoints[:, 2] > CONFIG['keypoint_threshold']]
            if len(valid_points) > 0:
                center = np.mean(valid_points[:, :2], axis=0)
                centers.append(center)
            else:
                centers.append(None)
        
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        matched_persons = []
        used_ids = set()
        
        for i, center in enumerate(centers):
            if center is None:
                continue
                
            best_id = None
            best_distance = float('inf')
            
            # ‡∏´‡∏≤‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            for person_id, person_data in self.persons.items():
                if person_id in used_ids:
                    continue
                    
                last_center = person_data['last_center']
                distance = np.linalg.norm(center - last_center)
                
                if distance < self.max_distance and distance < best_distance:
                    best_distance = distance
                    best_id = person_id
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á ID ‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ ID ‡πÄ‡∏î‡∏¥‡∏°
            if best_id is None:
                person_id = self.next_id
                self.next_id += 1
                self.persons[person_id] = {
                    'keypoints_history': deque(maxlen=CONFIG['frame_buffer_size']),
                    'fall_history': deque(maxlen=CONFIG['fall_buffer_size']),
                    'last_center': center,
                    'alert_cooldown': 0,
                    'last_seen': 0
                }
            else:
                person_id = best_id
                used_ids.add(person_id)
                self.persons[person_id]['last_center'] = center
                self.persons[person_id]['last_seen'] = 0
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° keypoints ‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
            self.persons[person_id]['keypoints_history'].append(keypoints_list[i])
            matched_persons.append((person_id, keypoints_list[i]))
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏´‡∏≤‡∏Å‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        to_remove = []
        for person_id in list(self.persons.keys()):
            if person_id not in used_ids:
                self.persons[person_id]['last_seen'] += 1
                if self.persons[person_id]['last_seen'] > 30:
                    to_remove.append(person_id)
        
        for person_id in to_remove:
            if person_id in self.persons:
                del self.persons[person_id]
        
        return matched_persons

class FallDetector:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß"""
    
    def __init__(self):
        # ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (COCO format)
        self.keypoint_names = [
            'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
            'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
            'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
            'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
        ]
        
        # ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        self.body_parts = {
            'head': [0, 1, 2, 3, 4],
            'torso': [5, 6, 11, 12],
            'arms': [7, 8, 9, 10],
            'legs': [13, 14, 15, 16]
        }
    
    def get_body_angle(self, keypoints):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏•‡∏≥‡∏ï‡∏±‡∏ß"""
        shoulder_points = []
        hip_points = []
        
        # ‡πÑ‡∏´‡∏•‡πà
        if keypoints[5][2] > CONFIG['keypoint_threshold']:  # left shoulder
            shoulder_points.append(keypoints[5])
        if keypoints[6][2] > CONFIG['keypoint_threshold']:  # right shoulder
            shoulder_points.append(keypoints[6])
        
        # ‡∏™‡∏∞‡πÇ‡∏û‡∏Å
        if keypoints[11][2] > CONFIG['keypoint_threshold']:  # left hip
            hip_points.append(keypoints[11])
        if keypoints[12][2] > CONFIG['keypoint_threshold']:  # right hip
            hip_points.append(keypoints[12])
        
        if len(shoulder_points) >= 1 and len(hip_points) >= 1:
            shoulder_center = np.mean([sp[:2] for sp in shoulder_points], axis=0)
            hip_center = np.mean([hp[:2] for hp in hip_points], axis=0)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
            dy = hip_center[0] - shoulder_center[0]  # y ‡πÄ‡∏õ‡πá‡∏ô vertical
            dx = hip_center[1] - shoulder_center[1]  # x ‡πÄ‡∏õ‡πá‡∏ô horizontal
            
            angle = math.atan2(abs(dx), abs(dy)) * 180 / math.pi
            return angle
        
        return None
    
    def get_body_center(self, keypoints):
        """‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢"""
        torso_points = []
        for idx in self.body_parts['torso']:
            if idx < len(keypoints) and keypoints[idx][2] > CONFIG['keypoint_threshold']:
                torso_points.append(keypoints[idx][:2])
        
        if len(torso_points) >= 2:
            return np.mean(torso_points, axis=0)
        return None
    
    def calculate_body_ratio(self, keypoints):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á)"""
        # ‡∏´‡∏≤‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢
        valid_points = keypoints[keypoints[:, 2] > CONFIG['keypoint_threshold']]
        
        if len(valid_points) < 3:
            return None
        
        min_y, max_y = np.min(valid_points[:, 0]), np.max(valid_points[:, 0])
        min_x, max_x = np.min(valid_points[:, 1]), np.max(valid_points[:, 1])
        
        height = max_y - min_y
        width = max_x - min_x
        
        if width > 0:
            return height / width
        return None
    
    def detect_rapid_movement(self, person_keypoints_history):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß"""
        if len(person_keypoints_history) < 3:
            return False, 0
        
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡πÉ‡∏ô 3 ‡πÄ‡∏ü‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        centers = []
        for keypoints in list(person_keypoints_history)[-3:]:
            center = self.get_body_center(keypoints)
            if center is not None:
                centers.append(center)
        
        if len(centers) < 3:
            return False, 0
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
        vertical_speeds = []
        for i in range(1, len(centers)):
            dy = centers[i][0] - centers[i-1][0]  # ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
            vertical_speeds.append(dy)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
        avg_speed = np.mean(vertical_speeds)
        max_speed = np.max(vertical_speeds)
        
        # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
        rapid_fall = avg_speed > 0.08 or max_speed > 0.12
        confidence = min(avg_speed * 10, max_speed * 8)
        
        return rapid_fall, confidence
    
    def analyze_pose_changes(self, person_keypoints_history):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á"""
        if len(person_keypoints_history) < 2:
            return 0
        
        current_keypoints = person_keypoints_history[-1]
        prev_keypoints = person_keypoints_history[-2]
        
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏°‡∏∏‡∏°‡∏•‡∏≥‡∏ï‡∏±‡∏ß
        current_angle = self.get_body_angle(current_keypoints)
        prev_angle = self.get_body_angle(prev_keypoints)
        
        if current_angle is not None and prev_angle is not None:
            angle_change = abs(current_angle - prev_angle)
            if angle_change > 30:  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 30 ‡∏≠‡∏á‡∏®‡∏≤
                return 2
            elif angle_change > 15:
                return 1
        
        return 0
    
    def detect_fall(self, person_data):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏´‡∏ô‡∏∂‡πà‡∏á"""
        keypoints_history = person_data['keypoints_history']
        
        if len(keypoints_history) == 0:
            return False, 0, ""
        
        current_keypoints = keypoints_history[-1]
        fall_score = 0
        reasons = []
        
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
        rapid_fall, rapid_score = self.detect_rapid_movement(keypoints_history)
        if rapid_fall:
            fall_score += rapid_score * 2
            reasons.append(f"‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ({rapid_score:.2f})")
        
        # 2. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏°‡∏∏‡∏°‡∏•‡∏≥‡∏ï‡∏±‡∏ß
        body_angle = self.get_body_angle(current_keypoints)
        if body_angle is not None:
            if body_angle > 60:  # ‡∏•‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 60 ‡∏≠‡∏á‡∏®‡∏≤
                angle_score = (body_angle - 60) / 30  # normalize
                fall_score += angle_score
                reasons.append(f"‡∏•‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏µ‡∏¢‡∏á ({body_angle:.1f}¬∞)")
        
        # 3. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢
        body_ratio = self.calculate_body_ratio(current_keypoints)
        if body_ratio is not None:
            if body_ratio < 1.2:  # ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á ‡∏ï‡πà‡∏≥ = ‡∏ô‡∏≠‡∏ô
                ratio_score = (1.2 - body_ratio) * 2
                fall_score += ratio_score
                reasons.append(f"‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ ({body_ratio:.2f})")
        
        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏•‡∏≥‡∏ï‡∏±‡∏ß
        head_indices = [0, 1, 2, 3, 4]  # ‡∏à‡∏∏‡∏î‡∏´‡∏±‡∏ß
        torso_indices = [5, 6, 11, 12]  # ‡∏à‡∏∏‡∏î‡∏•‡∏≥‡∏ï‡∏±‡∏ß
        
        head_points = [current_keypoints[i] for i in head_indices 
                      if i < len(current_keypoints) and current_keypoints[i][2] > CONFIG['keypoint_threshold']]
        torso_points = [current_keypoints[i] for i in torso_indices 
                       if i < len(current_keypoints) and current_keypoints[i][2] > CONFIG['keypoint_threshold']]
        
        if len(head_points) >= 1 and len(torso_points) >= 2:
            avg_head_y = np.mean([hp[0] for hp in head_points])
            avg_torso_y = np.mean([tp[0] for tp in torso_points])
            
            if avg_head_y > avg_torso_y + 0.1:  # ‡∏´‡∏±‡∏ß‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏•‡∏≥‡∏ï‡∏±‡∏ß‡∏°‡∏≤‡∏Å
                head_score = (avg_head_y - avg_torso_y - 0.1) * 5
                fall_score += head_score
                reasons.append(f"‡∏´‡∏±‡∏ß‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏•‡∏≥‡∏ï‡∏±‡∏ß ({head_score:.2f})")
        
        # 5. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á
        pose_change_score = self.analyze_pose_changes(keypoints_history)
        if pose_change_score > 0:
            fall_score += pose_change_score
            reasons.append(f"‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ({pose_change_score})")
        
        # 6. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏° (‡∏Ñ‡∏ô‡∏•‡πâ‡∏°‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏™‡πà‡∏ß‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°)
        body_center = self.get_body_center(current_keypoints)
        if body_center is not None and body_center[0] > 0.7:  # ‡∏≠‡∏¢‡∏π‡πà‡∏™‡πà‡∏ß‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°
            fall_score += 0.5
            reasons.append("‡∏≠‡∏¢‡∏π‡πà‡∏™‡πà‡∏ß‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏ü‡∏£‡∏°")
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        is_fallen = fall_score >= 2.0
        confidence = min(fall_score / 4.0, 1.0) * 100  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
        
        return is_fallen, confidence, "; ".join(reasons)

def detect_pose_optimized(image):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
    # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    height, width = image.shape[:2]
    if width > CONFIG['resize_width']:
        scale = CONFIG['resize_width'] / width
        new_width = CONFIG['resize_width']
        new_height = int(height * scale)
        image = tf.image.resize(image, [new_height, new_width])
    
    # Resize ‡πÅ‡∏•‡∏∞ normalize input
    input_image = tf.image.resize_with_pad(tf.expand_dims(image, axis=0), 
                                         CONFIG['input_size'], CONFIG['input_size'])
    input_image = tf.cast(input_image, dtype=tf.int32)
    
    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    outputs = movenet(input_image)
    keypoints = outputs['output_0'].numpy()
    
    # ‡∏ï‡∏±‡∏î batch dimension
    keypoints = keypoints[0]
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ confidence score ‡∏™‡∏π‡∏á‡∏û‡∏≠
    valid_detections = []
    for detection in keypoints:
        keypoint_data = detection[:51].reshape(17, 3)
        valid_keypoints = keypoint_data[keypoint_data[:, 2] > CONFIG['keypoint_threshold']]
        
        if len(valid_keypoints) >= CONFIG['min_keypoints']:
            valid_detections.append(keypoint_data)
    
    return valid_detections

def draw_optimized_pose_visualization(frame, tracked_persons, fall_results):
    """‡∏ß‡∏≤‡∏îkeypoints ‡πÅ‡∏•‡∏∞ skeleton ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥"""
    height, width, _ = frame.shape
    
    # ‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô (‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)
    person_colors = [
        (0, 255, 0),    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
        (255, 165, 0),  # ‡∏™‡πâ‡∏°
        (255, 0, 255),  # ‡∏°‡πà‡∏ß‡∏á
        (0, 255, 255),  # ‡∏ü‡πâ‡∏≤
        (255, 255, 0),  # ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
        (128, 0, 128)   # ‡∏°‡πà‡∏ß‡∏á‡πÄ‡∏Ç‡πâ‡∏°
    ]
    
    # ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
    connections = [
        # ‡∏•‡∏≥‡∏ï‡∏±‡∏ß‡∏´‡∏•‡∏±‡∏Å (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        (5, 6),   # ‡πÑ‡∏´‡∏•‡πà‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤
        (11, 12), # ‡∏™‡∏∞‡πÇ‡∏û‡∏Å‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤
        (5, 11),  # ‡πÑ‡∏´‡∏•‡πà‡∏ã‡πâ‡∏≤‡∏¢-‡∏™‡∏∞‡πÇ‡∏û‡∏Å‡∏ã‡πâ‡∏≤‡∏¢
        (6, 12),  # ‡πÑ‡∏´‡∏•‡πà‡∏Ç‡∏ß‡∏≤-‡∏™‡∏∞‡πÇ‡∏û‡∏Å‡∏Ç‡∏ß‡∏≤
        
        # ‡πÅ‡∏Ç‡∏ô
        (5, 7), (7, 9),   # ‡πÅ‡∏Ç‡∏ô‡∏ã‡πâ‡∏≤‡∏¢
        (6, 8), (8, 10),  # ‡πÅ‡∏Ç‡∏ô‡∏Ç‡∏ß‡∏≤
        
        # ‡∏Ç‡∏≤
        (11, 13), (13, 15),  # ‡∏Ç‡∏≤‡∏ã‡πâ‡∏≤‡∏¢
        (12, 14), (14, 16),  # ‡∏Ç‡∏≤‡∏Ç‡∏ß‡∏≤
        
        # ‡∏´‡∏±‡∏ß (‡∏ß‡∏≤‡∏î‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á)
        (0, 1), (0, 2),      # ‡∏à‡∏°‡∏π‡∏Å-‡∏ï‡∏≤
        (1, 3), (2, 4),      # ‡∏ï‡∏≤-‡∏´‡∏π
    ]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fall results ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    fall_dict = {result['person_id']: result for result in fall_results}
    
    # ‡∏ß‡∏≤‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô
    for person_id, keypoints in tracked_persons:
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ
        base_color = person_colors[person_id % len(person_colors)]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
        fall_result = fall_dict.get(person_id, {'is_fallen': False, 'confidence': 0})
        
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏î‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
        if fall_result['is_fallen']:
            skeleton_color = (0, 0, 255)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö skeleton
            keypoint_color = (0, 0, 255)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö keypoints
        else:
            skeleton_color = base_color
            keypoint_color = base_color
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û)
        keypoint_positions = []
        keypoint_scores = []
        
        for kp in keypoints:
            y, x, score = kp
            cx, cy = int(x * width), int(y * height)
            keypoint_positions.append((cx, cy))
            keypoint_scores.append(score)
        
        # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° (skeleton) ‡∏Å‡πà‡∏≠‡∏ô
        for connection in connections:
            kp1_idx, kp2_idx = connection
            
            if (kp1_idx < len(keypoint_scores) and kp2_idx < len(keypoint_scores) and
                keypoint_scores[kp1_idx] > CONFIG['confidence_threshold'] and 
                keypoint_scores[kp2_idx] > CONFIG['confidence_threshold']):
                
                pt1 = keypoint_positions[kp1_idx]
                pt2 = keypoint_positions[kp2_idx]
                
                # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                if connection in [(5, 6), (11, 12), (5, 11), (6, 12)]:  # ‡∏•‡∏≥‡∏ï‡∏±‡∏ß‡∏´‡∏•‡∏±‡∏Å
                    thickness = 3
                else:
                    thickness = 2
                
                cv2.line(frame, pt1, pt2, skeleton_color, thickness)
        
        # ‡∏ß‡∏≤‡∏î keypoints ‡∏ó‡∏±‡∏ö‡∏ö‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°
        for i, (pos, score) in enumerate(zip(keypoint_positions, keypoint_scores)):
            if score > CONFIG['confidence_threshold']:
                cx, cy = pos
                
                # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                if i in [5, 6, 11, 12]:  # ‡∏à‡∏∏‡∏î‡∏•‡∏≥‡∏ï‡∏±‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                    radius = 5
                elif i in [0]:  # ‡∏à‡∏°‡∏π‡∏Å
                    radius = 4
                else:
                    radius = 3
                
                # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏Ç‡∏≠‡∏ö
                cv2.circle(frame, (cx, cy), radius, keypoint_color, -1)
                cv2.circle(frame, (cx, cy), radius + 1, (255, 255, 255), 1)

def draw_fall_alert_only(frame, fall_results):
    """‡∏ß‡∏≤‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°"""
    fallen_persons = [result for result in fall_results if result['is_fallen']]
    
    if not fallen_persons:
        return
    
    height, width = frame.shape[:2]
    
    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö
    current_time = time.time()
    if int(current_time * 3) % 2:  # ‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
        cv2.rectangle(frame, (0, 0), (width, height), (0, 0, 255), 8)
    
    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å
    alert_text = "‚ö†Ô∏è FALL DETECTED! ‚ö†Ô∏è"
    text_size = cv2.getTextSize(alert_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0]
    text_x = (width - text_size[0]) // 2
    text_y = 50
    
    # ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    cv2.rectangle(frame, (text_x - 10, text_y - 35), 
                 (text_x + text_size[0] + 10, text_y + 10), (0, 0, 0), -1)
    cv2.putText(frame, alert_text, (text_x, text_y), 
               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å - ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    # ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
    cap = cv2.VideoCapture("H:\FallG\Fall_ex.mp4")
    
    if not cap.isOpened():
        print("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ")
        return
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CONFIG['resize_width'])
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CONFIG['resize_height'])
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå
    person_tracker = PersonTracker()
    fall_detector = FallDetector()
    
    print("=== Optimized Fall Detection System ===")
    print("‡∏Å‡∏î ESC ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    print("=== ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•... ===")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‡∏à‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡πÑ‡∏î‡πâ")
            break
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ü‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        if frame.shape[1] > CONFIG['resize_width']:
            scale = CONFIG['resize_width'] / frame.shape[1]
            new_width = CONFIG['resize_width']
            new_height = int(frame.shape[0] * scale)
            frame = cv2.resize(frame, (new_width, new_height))
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        tensor_frame = tf.convert_to_tensor(rgb_frame)
        keypoints_list = detect_pose_optimized(tensor_frame)
        
        # ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
        tracked_persons = person_tracker.update(keypoints_list)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
        fall_results = []
        for person_id, keypoints in tracked_persons:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ person_id ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô tracker ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if person_id not in person_tracker.persons:
                continue
            
            person_data = person_tracker.persons[person_id]
            
            # ‡∏•‡∏î cooldown
            if person_data['alert_cooldown'] > 0:
                person_data['alert_cooldown'] -= 1
            
            is_fallen, confidence, reason = fall_detector.detect_fall(person_data)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
            person_data['fall_history'].append(is_fallen)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
            recent_falls = list(person_data['fall_history'])[-3:]  # 3 ‡πÄ‡∏ü‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            consistent_fall = sum(recent_falls) >= 2  # ‡∏•‡πâ‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡πÉ‡∏ô 3 ‡πÄ‡∏ü‡∏£‡∏°
            
            # ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
            if consistent_fall and person_data['alert_cooldown'] <= 0:
                print(f"üö® FALL ALERT - Person {person_id}: {confidence:.1f}%")
                person_data['alert_cooldown'] = CONFIG['alert_cooldown']
            
            fall_results.append({
                'person_id': person_id,
                'is_fallen': consistent_fall,
                'confidence': confidence,
                'reason': reason
            })
        
        # ‡∏ß‡∏≤‡∏î keypoints ‡πÅ‡∏•‡∏∞ skeleton
        draw_optimized_pose_visualization(frame, tracked_persons, fall_results)
        
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
        draw_fall_alert_only(frame, fall_results)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ü‡∏£‡∏°
        cv2.imshow('Fall Detection System', frame)
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC key
            break
    
    # ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£
    cap.release()
    cv2.destroyAllWindows()
    print("‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

if __name__ == "__main__":
    main()  